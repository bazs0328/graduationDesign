# LLM provider: openai, gemini, or deepseek
LLM_PROVIDER=openai

# Embedding provider: openai, gemini, deepseek, or bgem3
EMBEDDING_PROVIDER=openai

# OpenAI
OPENAI_API_KEY=your_openai_key
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Gemini (Google)
GOOGLE_API_KEY=your_google_key
GEMINI_MODEL=gemini-1.5-flash
GEMINI_EMBEDDING_MODEL=text-embedding-004

# DeepSeek (OpenAI-compatible)
DEEPSEEK_API_KEY=your_deepseek_key
# base_url can be https://api.deepseek.com or https://api.deepseek.com/v1
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
DEEPSEEK_MODEL=deepseek-chat
# Optional: set an embedding model if your DeepSeek plan supports embeddings.
# If not set, the system will try to fall back to OpenAI embeddings (OPENAI_API_KEY).
DEEPSEEK_EMBEDDING_MODEL=

# BGE-M3 (local embedding)
BGE_M3_MODEL=BAAI/bge-m3
EMBEDDINGS_DEVICE=cpu
HF_TOKEN=your_hf_token

# App
DATA_DIR=data
CHUNK_SIZE=1000
CHUNK_OVERLAP=150
QA_TOP_K=4
QA_FETCH_K=12
QA_BM25_K=6
RAG_MODE=hybrid
RAG_DENSE_WEIGHT=0.7
RAG_BM25_WEIGHT=0.3
